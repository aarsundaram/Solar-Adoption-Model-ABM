{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd0b2c46f39afd024b40309f4d81464c458674b504768a264b780ab4385ec8101ea",
   "display_name": "Python 3.6.12 64-bit ('networksci': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 80280 entries, 0 to 80279\nData columns (total 14 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   rand_point  80280 non-null  float64\n 1   case_id     80280 non-null  int64  \n 2   bgid        80280 non-null  int64  \n 3   age         80280 non-null  object \n 4   income      80280 non-null  object \n 5   sample_inc  80280 non-null  float64\n 6   ami_catego  80280 non-null  int64  \n 7   tract       80280 non-null  int64  \n 8   elec_consu  80280 non-null  float64\n 9   TRACTCE10   80280 non-null  float64\n 10  BLOCKCE10   80280 non-null  float64\n 11  GEOID10     80280 non-null  float64\n 12  geometry    80280 non-null  object \n 13  household_  80280 non-null  int64  \ndtypes: float64(6), int64(5), object(3)\nmemory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import gower \n",
    "import dill\n",
    "from pathos.multiprocessing import ProcessingPool\n",
    "\n",
    "path = os.getcwd()\n",
    "path\n",
    "rootpath = '/Users/rtseinstein/Documents/GitHub/Solar-Adoption-Agent-based-Model/'\n",
    "\n",
    "survey = pd.read_csv(rootpath+'data/survey/gps_final_scored_phase3.csv')\n",
    "survey['PEOPLE_TOT_3PLUS']=survey['PEOPLE_TOT_3PLUS'].fillna(0)\n",
    "#survey.info()\n",
    "\n",
    "#read in the main households data\n",
    "households = pd.read_csv(rootpath+'data/households_main/households_main.csv')\n",
    "households = households.drop(columns='Unnamed: 0')\n",
    "\n",
    "demographics = survey[['CASE_ID','AGE_BINNED','INCOME_BINNED','PEOPLE_TOT_3PLUS']].set_index('CASE_ID')\n",
    "tpb_attributes = survey[['CASE_ID','attitude','subnorms','pbc']].set_index('CASE_ID')\n",
    "\n",
    "## need to map the numbers to categories in the survey datatable\n",
    "income_map= {1:'less75k',2:'less75k',3:'75to100k',4:'100to150k',5:'150kplus'}\n",
    "age_map = {1.:'25to44',2.:'45to54',3.:'55to64',4.:'65plus'}\n",
    "#need to do this mapping in the households data\n",
    "size_map={'1person':0.,'2person':0.,'3person':np.random.choice([0.,1.]),'4person':1.,'5person':1.,'6person':1.,'7plus':1.}\n",
    "\n",
    "demographics['INCOME_BINNED']=demographics['INCOME_BINNED'].map(income_map)\n",
    "demographics['AGE_BINNED']=demographics['AGE_BINNED'].map(age_map)\n",
    "\n",
    "households = households.dropna()\n",
    "households.drop(households.tail(1).index,inplace=True) # drop last n rows\n",
    "\n",
    "## add the required household row as last row in the demographics survey data\n",
    "demographics = demographics.rename(columns={'AGE_BINNED':'age','INCOME_BINNED':'income','PEOPLE_TOT_3PLUS':'household_'})\n",
    "\n",
    "filenames=[]\n",
    "for i in range(24):\n",
    "    filenames.append('df_'+str(i+1)+'.csv')\n",
    "\n",
    "\n",
    "#definition of initialize function \n",
    "def initialize(df,df_name):\n",
    "    print(f'beginning initialization of {df_name}')\n",
    "    attitude={}\n",
    "    subnorms={}\n",
    "    pbc={}\n",
    "    errorids = []\n",
    "    for household_case in list(df.index):\n",
    "        new_record = df.loc[household_case]\n",
    "\n",
    "        #add to last row of demographics data\n",
    "        demo = demographics\n",
    "        demo['household_'] = demo['household_'].astype('object')\n",
    "        demo = demo.append(new_record)\n",
    "\n",
    "        #calculate gower's distance\n",
    "        new_row = gower.gower_matrix(demo)[-1]\n",
    "        #new_row\n",
    "\n",
    "        indexes = list(demo.index)\n",
    "\n",
    "        temp = min(new_row)\n",
    "        res = [i for i, j in enumerate(new_row) if j == temp]\n",
    "        #res\n",
    "\n",
    "        caseids = []\n",
    "        for i in res:\n",
    "            caseids.append(indexes[i])\n",
    "\n",
    "\n",
    "        c = []\n",
    "        for i in caseids:\n",
    "            c.append(int(i))\n",
    "\n",
    "        atts = []\n",
    "        sn = []\n",
    "        p = []\n",
    "        try:\n",
    "            for i in c:\n",
    "                if i!=c[-1]:\n",
    "                    atts.append(tpb_attributes.loc[i]['attitude'])\n",
    "                    sn.append(tpb_attributes.loc[i]['subnorms'])\n",
    "                    p.append(tpb_attributes.loc[i]['pbc'])\n",
    "            \n",
    "            attitude[household_case]= np.random.choice(atts)\n",
    "            subnorms[household_case]=np.random.choice(sn)\n",
    "            pbc[household_case]=np.random.choice(p)\n",
    "        except:\n",
    "            attitude[household_case]= 0\n",
    "            subnorms[household_case]=0\n",
    "            pbc[household_case]=0\n",
    "            print(household_case)\n",
    "            errorids.append(household_case)\n",
    "            continue\n",
    "    \n",
    "    df['attitude']= list(attitude.values())\n",
    "    df['subnorms']= list(subnorms.values())\n",
    "    df['pbc']= list(pbc.values())\n",
    "\n",
    "    df.to_csv(rootpath+f'data/initialization_subsets_24/{df_name}_initialized.csv')\n",
    "    print(f'finished exporting the initialized file of {df_name}')\n",
    "\n",
    "pool = ProcessingPool()\n",
    "results = pool.map(initialize(,))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80280 entries, 000033813 to 000061348\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   age         80280 non-null  object\n",
      " 1   income      80280 non-null  object\n",
      " 2   household_  80280 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 2.4+ MB\n",
      "ipykernel_launcher:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "ipykernel_launcher:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "household_demographics= households[['case_id','age','income','household_']]\n",
    "new_caseids=[]\n",
    "for i in list(household_demographics['case_id']):\n",
    "    new_caseids.append(str(i).zfill(9))\n",
    "\n",
    "household_demographics['case_id']= new_caseids\n",
    "household_demographics['household_']=household_demographics['household_'].astype('object')\n",
    "household_demographics= household_demographics.rename(columns={'case_id':'CASE_ID'})\n",
    "household_demographics = household_demographics.set_index('CASE_ID')\n",
    "\n",
    "\n",
    "household_demographics.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "## separate the main file into several subsets of 3345 each: 24 files \n",
    "for i in list(range(24)):\n",
    "    df= np.array_split(household_demographics, 24)[i]\n",
    "    #df.to_csv(rootpath+f'data/initialization_subsets_24/df_{i+1}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "ipykernel_launcher:57: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:58: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nipykernel_launcher:59: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# for each file, read and call the function to initialize\n",
    "#need: demographics file and tpb_attributes file of the survey data \n",
    "\n",
    "\n",
    "df_sample = df.head(10) \n",
    "initialize(df_sample,'df_sample_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['df_1.csv',\n",
       " 'df_2.csv',\n",
       " 'df_3.csv',\n",
       " 'df_4.csv',\n",
       " 'df_5.csv',\n",
       " 'df_6.csv',\n",
       " 'df_7.csv',\n",
       " 'df_8.csv',\n",
       " 'df_9.csv',\n",
       " 'df_10.csv',\n",
       " 'df_11.csv',\n",
       " 'df_12.csv',\n",
       " 'df_13.csv',\n",
       " 'df_14.csv',\n",
       " 'df_15.csv',\n",
       " 'df_16.csv',\n",
       " 'df_17.csv',\n",
       " 'df_18.csv',\n",
       " 'df_19.csv',\n",
       " 'df_20.csv',\n",
       " 'df_21.csv',\n",
       " 'df_22.csv',\n",
       " 'df_23.csv',\n",
       " 'df_24.csv']"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "filenames= glob.glob(rootpath+'data/initialization_subsets_24/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'df_14'"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "filenames[0][100:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}